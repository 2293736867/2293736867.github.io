<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://2293736867.github.io</id>
    <title>氷泠&apos;s blog</title>
    <updated>2020-08-22T16:43:41.525Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://2293736867.github.io"/>
    <link rel="self" href="https://2293736867.github.io/atom.xml"/>
    <subtitle>我配不上你，
纵然很努力。</subtitle>
    <logo>https://2293736867.github.io/images/avatar.png</logo>
    <icon>https://2293736867.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 氷泠&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[每日分享 第71期]]></title>
        <id>https://2293736867.github.io/post/mei-ri-fen-xiang-di-71-qi/</id>
        <link href="https://2293736867.github.io/post/mei-ri-fen-xiang-di-71-qi/">
        </link>
        <updated>2020-08-26T07:11:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="每日鸡汤">每日鸡汤</h1>
<blockquote>
<p>我对生活充满向往，生活对我虽远必诛。</p>
</blockquote>
<h1 id="每日冷知识">每日冷知识</h1>
<blockquote>
<p>字母E是英文中最常见的字母。所有单词中大约11%都有字母E，光原文这一句话里就出现了12次。</p>
</blockquote>
<h1 id="每日诗词">每日诗词</h1>
<blockquote>
<p>古今多少事，渔唱起三更。<br>
——陈与义《临江仙·夜登小阁忆洛中旧游》</p>
</blockquote>
<h1 id="每日一句">每日一句</h1>
<blockquote>
<p>萤火之光看起来比平常更耀眼是错觉吗？今宵会成为永夜的吧。</p>
</blockquote>
<h1 id="每日音乐">每日音乐</h1>
<blockquote>
<p><a href="https://music.163.com/#/song?id=1313107233">活该-徐真真/花粥</a></p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="https://2293736867.github.io/post-images/1598114411835.jpg" alt="" loading="lazy"></figure>
<blockquote>
<p>最后我没有看不开<br>
领悟着生活的无奈<br>
我们计划的未来被现实冲淡我有一点遗憾<br>
可是我从来都不乖<br>
我也不会再让你猜<br>
这不圆满的结果都是我活该</p>
</blockquote>
<blockquote>
<p>如果说开始的时候没有任何期待<br>
那到了该死的那天可能只有依赖<br>
当初同款发带配上同款AJ一代<br>
有多少爱情最后都被欲望几百<br>
只能把你送的礼物收进白色箱子里<br>
装作若无其事其实只是不想伤自己<br>
再多漂亮外壳都没法跟你的样子比<br>
走遍了大街小巷也找不到你的相似体<br>
曾和你一起憧憬未来有多灿烂<br>
一次次错误选择后一切变黯淡<br>
总是用骂战<br>
掩饰着情感<br>
却总在看清真相以后都会心软</p>
</blockquote>
<blockquote>
<p>最后我没有看不开<br>
领悟着生活的无奈<br>
我们计划的未来被现实冲淡我有一点遗憾<br>
可是我从来都不乖<br>
我也不会再让你猜<br>
这不圆满的结果都是我活该</p>
</blockquote>
<blockquote>
<p>你说要认真在一起<br>
一直在一起<br>
我承认在这个世界没有人能真的代替你<br>
没法真的忘记你<br>
只好尽力骗自己<br>
可惜一旦喝醉我的眼泪全部都是你<br>
wooo<br>
都怪我活该<br>
把身体挪开<br>
期待的色彩<br>
只剩下空白<br>
用力去破坏<br>
崩溃的心态<br>
相爱的两颗心为何要相互伤害<br>
是否还有人在耳边给你忠告<br>
是否还有人在凌晨给你拥抱<br>
是否还能为了见你守在你的通道<br>
还拎着打包好的中药<br>
多年以后同样的秋风季<br>
是否还能再和老去的你相遇<br>
曾经的悲伤都已藏箱底<br>
自由漫步在那金黄色阳光里</p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://2293736867.github.io/post-images/1598114418399.jpeg" alt="" loading="lazy"></figure>
<blockquote>
<p>最后我没有看不开<br>
领悟着生活的无奈<br>
我们计划的未来被现实冲淡我有一点遗憾<br>
可是我从来都不乖<br>
我也不会再让你猜<br>
这不圆满的结果都是我活该<br>
你也活该</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[每日分享 第70期]]></title>
        <id>https://2293736867.github.io/post/mei-ri-fen-xiang-di-70-qi/</id>
        <link href="https://2293736867.github.io/post/mei-ri-fen-xiang-di-70-qi/">
        </link>
        <updated>2020-08-26T07:10:19.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://2293736867.github.io/post-images/1598113535127.jpeg" alt="" loading="lazy"></figure>
<h1 id="每日鸡汤">每日鸡汤</h1>
<blockquote>
<p>命只有一条，但要命的事，可不止一件。</p>
</blockquote>
<h1 id="每日冷知识">每日冷知识</h1>
<blockquote>
<p>新西兰其实是一块被海水淹没的更大面积大陆的一部分。这块大陆名为“西兰大陆”，知道人类进入太空后俯瞰地球时才发现。一些科学家认为它应该被正式称为世界的第八大陆。</p>
</blockquote>
<h1 id="每日诗词">每日诗词</h1>
<blockquote>
<p>香汗薄衫凉，凉衫薄汗香。<br>
——苏轼《菩萨蛮·回文夏闺怨》</p>
</blockquote>
<h1 id="每日一句">每日一句</h1>
<blockquote>
<p>别人的幸福，你的地狱。</p>
</blockquote>
<h1 id="每日音乐">每日音乐</h1>
<blockquote>
<p><a href="https://music.163.com/#/song?id=1447998357">活该-谌宥</a></p>
</blockquote>
<blockquote>
<p>故事无法倒带不能重来<br>
把时间锁起来却成空白<br>
从开始到现在<br>
我还期待死性不改</p>
</blockquote>
<blockquote>
<p>感情本来就是爱与被爱<br>
但剧本的结尾缺了一块<br>
你把我遗留在<br>
灰色地带只剩阴霾</p>
</blockquote>
<blockquote>
<p>我拼了命去爱<br>
换一句活该<br>
只能埋头痛苦<br>
像一个小孩<br>
曾对你的依赖<br>
和累积的伤害<br>
该怎么去释怀<br>
在旧梦里挣扎<br>
我还醒不来<br>
我不哭也不笑<br>
已成为常态<br>
不愿把手松开<br>
去拥抱未来<br>
是我活该</p>
</blockquote>
<blockquote>
<p>感情本来就是爱与被爱<br>
但剧本的结尾缺了一块<br>
你把我遗留在<br>
灰色地带只剩阴霾</p>
</blockquote>
<blockquote>
<p>我拼了命去爱<br>
换一句活该<br>
只能埋头痛苦<br>
像一个小孩<br>
曾对你的依赖<br>
和累积的伤害<br>
该怎么去释怀<br>
在旧梦里挣扎<br>
我还醒不来<br>
我不哭也不笑<br>
已成为常态<br>
不愿把手松开<br>
去拥抱未来<br>
是我活该</p>
</blockquote>
<blockquote>
<p>拼了命去爱<br>
换一句活该<br>
只能埋头痛苦<br>
像一个小孩<br>
曾对你的依赖<br>
和累积的伤害<br>
该怎么去释怀<br>
在旧梦里挣扎<br>
我还醒不来<br>
我不哭也不笑<br>
已成为常态<br>
不愿把手松开<br>
去拥抱未来<br>
是我活该</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[每日分享 第69期]]></title>
        <id>https://2293736867.github.io/post/mei-ri-fen-xiang-di-69-qi/</id>
        <link href="https://2293736867.github.io/post/mei-ri-fen-xiang-di-69-qi/">
        </link>
        <updated>2020-08-25T15:25:13.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://2293736867.github.io/post-images/1597851811937.jpeg" alt="" loading="lazy"></figure>
<h1 id="每日鸡汤">每日鸡汤</h1>
<blockquote>
<p>别说你一无所有，你还有一身债。</p>
</blockquote>
<h1 id="每日冷知识">每日冷知识</h1>
<blockquote>
<p>有的鲨鱼寿命长达500年。格陵兰鲨是所有脊椎动物中已知寿命最长的动物，直到它们约150岁时才达到性成熟。</p>
</blockquote>
<h1 id="每日诗词">每日诗词</h1>
<blockquote>
<p>梧桐树，三更雨，不道离情正苦。<br>
——温庭筠《更漏子·玉炉香》</p>
</blockquote>
<h1 id="每日一句">每日一句</h1>
<blockquote>
<p>我想拥有温柔，不仅仅止于表面的伪装。</p>
</blockquote>
<h1 id="每日音乐">每日音乐</h1>
<blockquote>
<p><a href="https://www.lizhi.fm/1975387/2691378352453205510">辞九门回忆-冰幽/解忧草</a></p>
</blockquote>
<figure data-type="image" tabindex="2"><img src="https://2293736867.github.io/post-images/1597851823365.jpeg" alt="" loading="lazy"></figure>
<blockquote>
<p>一曲定重楼<br>
一眼半生筹<br>
看的全都是那诡谲云涌<br>
入得此门不回首<br>
无需宣之于口<br>
我对案再拜那风雨飘泼的残陋<br>
再聚首</p>
</blockquote>
<blockquote>
<p>戏子多秋<br>
可怜一处情深旧<br>
满座衣冠皆老朽<br>
黄泉故事无止休<br>
戏无骨难左右<br>
换过一折又重头<br>
只道最是人间不能留<br>
误闯天家<br>
劝余放下手中砂<br>
张口欲唱声却哑<br>
粉面披衣叫个假<br>
怜余来安座下<br>
不敢沾染佛前茶<br>
只作凡人赴雪月风花</p>
</blockquote>
<blockquote>
<p>绕过胭脂楼<br>
打散结发扣<br>
唱的全都是那情深不寿<br>
入得此门不回首<br>
无需宣之于口<br>
我对镜遮掩那风雨飘泼的残陋<br>
碑已旧</p>
</blockquote>
<blockquote>
<p>戏子多秋<br>
可怜一处情深旧<br>
满座衣冠皆老朽<br>
黄泉故事无止休<br>
戏无骨难左右<br>
换过一折又重头<br>
只道最是人间不能留<br>
误闯天家<br>
劝余放下手中砂<br>
送那人御街打马<br>
才子佳人断佳话<br>
怜余来苦咽下<br>
求不得佛前茶<br>
只留三寸土种二月花</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[每日分享 第68期]]></title>
        <id>https://2293736867.github.io/post/mei-ri-fen-xiang-di-68-qi/</id>
        <link href="https://2293736867.github.io/post/mei-ri-fen-xiang-di-68-qi/">
        </link>
        <updated>2020-08-24T15:24:55.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://2293736867.github.io/post-images/1597851904108.jpeg" alt="" loading="lazy"></figure>
<h1 id="每日鸡汤">每日鸡汤</h1>
<blockquote>
<p>如果你不珍惜我，那么过了这个村，我在下一个村等你。</p>
</blockquote>
<h1 id="每日冷知识">每日冷知识</h1>
<blockquote>
<p>去年今夜，同醉月明花树下。<br>
——吕本中《减字木兰花·去年今夜》</p>
</blockquote>
<h1 id="每日诗词">每日诗词</h1>
<blockquote>
<p>考拉的指纹各不相同，黑猩猩和大猩猩也是如此。不过考拉的指纹和人类的极为相似，就连经验最为老道的法医也得花点时间才能分辨哪个是考拉的指纹，哪个是人类的指纹。</p>
</blockquote>
<h1 id="每日一句">每日一句</h1>
<blockquote>
<p>自己永远是孤单的，但你可以让其他人变得不孤单。</p>
</blockquote>
<h1 id="每日音乐">每日音乐</h1>
<blockquote>
<p><a href="https://music.163.com/#/song?id=481535597">看穿-任然</a></p>
</blockquote>
<blockquote>
<p>本来是很普通的聚餐<br>
因为你<br>
竟然精心打扮<br>
不过你大方问候<br>
心突然混乱<br>
竟然你还是一眼把我看穿</p>
</blockquote>
<blockquote>
<p>每个人毫不顾忌调侃<br>
气氛温暖得让我有些心酸<br>
好想你后来已经<br>
把伤痕顺其自然<br>
留我一个人进退两难</p>
</blockquote>
<blockquote>
<p>原来我这么勇敢<br>
能安静接受答案<br>
有些事没有<br>
当初想象得那么难<br>
两人的感情<br>
怎么可以<br>
一人追赶<br>
故事早就该停在那次离散<br>
Goodbye</p>
</blockquote>
<blockquote>
<p>每个人毫不顾忌调侃<br>
气氛温暖得让我有些心酸<br>
好像你后来已经<br>
把伤痕顺其自然</p>
</blockquote>
<blockquote>
<p>原来我这么勇敢<br>
能安静接受答案<br>
有些事没有<br>
当初想象得那么难<br>
两人的感情<br>
怎么可以<br>
一人追赶<br>
故事早就该停在那次离散<br>
原来我这么勇敢<br>
你平静我不哭喊<br>
你已经自由<br>
我何必再给你牵绊<br>
记忆里那段<br>
带着遗憾<br>
陪我灿烂<br>
在未来祝你能幸福美满<br>
晚安</p>
</blockquote>
<blockquote>
<p>原来我这么勇敢<br>
原来我这么勇敢<br>
你平静我不哭喊<br>
你已经自由<br>
我何必再给你牵绊<br>
记忆里那段<br>
带着遗憾<br>
陪我灿烂<br>
在未来祝你能幸福美满<br>
晚安</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[每日分享 第67期]]></title>
        <id>https://2293736867.github.io/post/mei-ri-fen-xiang-di-67-qi/</id>
        <link href="https://2293736867.github.io/post/mei-ri-fen-xiang-di-67-qi/">
        </link>
        <updated>2020-08-23T07:55:20.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://2293736867.github.io/post-images/1597651219898.jpeg" alt="" loading="lazy"></figure>
<h1 id="每日鸡汤">每日鸡汤</h1>
<blockquote>
<p>每当我找到成功的钥匙，就发现有人把锁芯给换了。</p>
</blockquote>
<h1 id="每日冷知识">每日冷知识</h1>
<blockquote>
<p>研究表明，人体中的细菌细胞（约39万亿个微生物细胞）比人类细胞（约30万亿个细胞）更多，甚至有多达40个人类基因被认为起源于细菌。</p>
</blockquote>
<h1 id="每日诗词">每日诗词</h1>
<blockquote>
<p>阴阴溪曲绿交加，小雨翻坪上浅沙。<br>
——晁冲之《春日》</p>
</blockquote>
<h1 id="每日一句">每日一句</h1>
<blockquote>
<p>我们生活在阴沟里，但有人依然仰望星空。</p>
</blockquote>
<h1 id="每日音乐">每日音乐</h1>
<blockquote>
<p><a href="https://music.163.com/#/song?id=493735012">无人之岛-任然</a></p>
</blockquote>
<blockquote>
<p>黑色的背后是黎明<br>
以为来日方长所以别把梦吵醒<br>
时间它继续飞行<br>
下一站机场门外<br>
拥抱你的背影<br>
蓝色的背后是纯净<br>
低下头俯瞰陆地上思念的眼睛<br>
生命中有些事情<br>
从没有原因说明<br>
一刹那的寂静</p>
</blockquote>
<blockquote>
<p>如果云层是天空的一封信<br>
能不能再听一听<br>
听你的声音<br>
就算是探秘(是贪玩而已)<br>
跟着潘彼得去无人岛旅行<br>
我不会怪你的<br>
天空一望无际<br>
是海洋的倒影<br>
蓝色一望无际<br>
我的你在哪里<br>
加入迷路了一定(记得)<br>
把思念装进漂流瓶(记得)<br>
快寄给我别让人担心</p>
</blockquote>
<blockquote>
<p>蓝色的背后是纯净(云淡风轻)<br>
低下头俯瞰陆地上思念的眼睛<br>
生命中有些事情(不能透明)<br>
从没有原因说明<br>
一刹那的寂静</p>
</blockquote>
<blockquote>
<p>如果云层是天空的一封信<br>
能不能再听一听<br>
听你的声音<br>
就算是探秘(是贪玩而已)<br>
跟着潘彼得去无人岛旅行<br>
我不会怪你的<br>
天空一望无际<br>
是海洋的倒影<br>
蓝色一望无际<br>
我的你在哪里<br>
假如迷了路一定(记得)<br>
把思念装进漂流瓶(记得)<br>
快寄给我别让人担心</p>
</blockquote>
<blockquote>
<p>如果云层是天空的一封信<br>
能不能再听一听<br>
听你的声音<br>
就算是探秘<br>
跟着潘彼得去无人岛旅行<br>
我不会怪你的<br>
天空一望无际<br>
是海洋的倒影<br>
蓝色一望无际<br>
我的你在哪里<br>
加入迷了路一定(记得)<br>
把思念装进漂流瓶(记得)<br>
快寄给我别让我担心</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[本地+分布式Hadoop完整搭建过程]]></title>
        <id>https://2293736867.github.io/post/ben-di-fen-bu-shi-hadoop-wan-zheng-da-jian-guo-cheng/</id>
        <link href="https://2293736867.github.io/post/ben-di-fen-bu-shi-hadoop-wan-zheng-da-jian-guo-cheng/">
        </link>
        <updated>2020-08-22T15:59:34.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#1-%E6%A6%82%E8%BF%B0">1 概述</a></li>
<li><a href="#2-%E6%9C%AF%E8%AF%AD%E4%BB%8B%E7%BB%8D">2 术语介绍</a></li>
<li><a href="#3-%E7%8E%AF%E5%A2%83">3 环境</a></li>
<li><a href="#4-hadoop%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F">4 <code>Hadoop</code>部署模式</a></li>
<li><a href="#5-%E5%AE%89%E8%A3%85%E5%89%8D%E5%87%86%E5%A4%87">5 安装前准备</a>
<ul>
<li><a href="#51-hadoop">5.1 <code>Hadoop</code></a></li>
<li><a href="#52-jdk">5.2 <code>JDK</code></a></li>
<li><a href="#53-%E8%99%9A%E6%8B%9F%E6%9C%BA">5.3 虚拟机</a></li>
<li><a href="#54-%E6%9C%8D%E5%8A%A1%E5%99%A8">5.4 服务器</a></li>
</ul>
</li>
<li><a href="#6-%E5%8A%A8%E6%89%8B%E5%90%A7">6 动手吧！</a></li>
<li><a href="#7-%E7%BB%93%E8%AF%AD">7 结语</a></li>
<li><a href="#8-%E5%8F%82%E8%80%83">8 参考</a></li>
</ul>
</p>
<h1 id="1-概述">1 概述</h1>
<p><code>Hadoop</code>在大数据技术体系中极为重要，被誉为是改变世界的7个Java项目之一（剩下6个是<code>Junit</code>、<code>Eclipse</code>、<code>Spring</code>、<code>Solr</code>、<code>HudsonAndJenkins</code>、<code>Android</code>），本篇文章以<code>Hadoop 3.3.0</code>官方文档为基础，首先会介绍<code>Hadoop</code>相关术语，包括<code>HDFS</code>，<code>MapReduce</code>等，接着会完整描述<code>Hadoop</code>的搭建过程，包括本地以及分布式集群的搭建。</p>
<h1 id="2-术语介绍">2 术语介绍</h1>
<ul>
<li><code>Hadoop</code>：<code>Hadoop</code>是<code>Apache</code>开发的分布式系统基础架构，用户可以在不了解分布式底层细节的情况下，开发分布式程序，充分利用集群的威力进行高速运算和存储</li>
<li><code>HDFS</code>：全称<code>Hadoop Distributed File System</code>，<code>Hadoop</code>分布式文件系统，被设计成适合运行在通用硬件上的分布式文件系统，具有高度容错性的特点，能提供高吞吐量的数据访问</li>
<li><code>MapReduce</code>：一个编程模型，用于大规模数据集的并行运算，是面向大数据并行处理的计算模型、架构以及平台。平台指的是允许使用普通商用服务器构成一个包含数十甚至数千个节点的分布和并行计算集群。架构指的是<code>MapReduce</code>提供了一个庞大但设计精良的并行计算软件框架，能自动完成计算任务的并行化处理，自动划分计算数据和计算任务。模型指的是借助于函数式编程语言的设计思想，提供了一种简便的并行程序设计方法</li>
<li><code>YARN</code>：<code>YARN</code>是<code>Hadoop</code>的一种资源管理器，一个通用的资源管理系统，可以为上层应用提供统一的资源管理以及调度，基本思想是将<code>JobTracker</code>的两个主要功能（<code>资源管理和作业调度/监控</code>）分离</li>
</ul>
<h1 id="3-环境">3 环境</h1>
<ul>
<li>操作环境：<code>Manjaro 20.0.3</code></li>
<li>虚拟机环境：<code>VirtualBox 6.1.10</code>+<code>CentOS-8.2.2004-x86_64-minimal</code> × 3</li>
<li><code>Hadoop 3.3.0</code>（<code>aarch64</code>+<code>x86_64</code>）</li>
<li><code>OpenJDK 11</code>（<code>aarch64</code>+<code>x86_64</code>）</li>
<li>服务器：<code>CentOS 8</code> × 3（<code>aarch64</code> × 1 + <code>x86_64</code> × 2）</li>
</ul>
<h1 id="4-hadoop部署模式">4 <code>Hadoop</code>部署模式</h1>
<p>首先来看一下<code>Hadoop</code>支持的部署模式，<code>Hadoop</code>集群搭建支持以下三种模式：</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20200816135739304.png#pic_center" alt="在这里插入图片描述" loading="lazy"></figure>
<ul>
<li>本地模式：默认模式，运行在单一Java进程中</li>
<li>伪分布模式：运行在一个节点中但是在不同的Java进程中</li>
<li>完全分布模式：运行在不同机器上的标准集群模式，利用多台主机部署<code>Hadoop</code></li>
</ul>
<h1 id="5-安装前准备">5 安装前准备</h1>
<h2 id="51-hadoop">5.1 <code>Hadoop</code></h2>
<p>官网下载<a href="https://hadoop.apache.org/releases.html">戳这里</a>，本文采用目前最新的<code>3.3.0</code>版本，注意如果服务器的架构为<code>aarch64</code>需要下载对应版本。</p>
<h2 id="52-jdk">5.2 <code>JDK</code></h2>
<p>关于<code>JDK</code>的选择，参考文末的链接：</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20200817173744414.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p><code>3.3</code>版本在运行时支持<code>Java11</code>，<code>3.2</code>（包括<code>3.2</code>）以下只支持<code>Java8</code>，另外也提到了现在<code>Hadoop</code>使用<code>OpenJDK</code>作为构建/测试以及发布的<code>JDK</code>，因此这里使用<code>OpenJDK11</code>，<a href="https://jdk.java.net/java-se-ri/11">戳这里</a>下载，如果服务器架构为<code>aarch64</code>可以使用<code>yum install</code>安装。</p>
<h2 id="53-虚拟机">5.3 虚拟机</h2>
<p>虚拟机用的是<code>Virtual Box</code>，<code>6.1.10</code>版本。</p>
<p>使用虚拟机是为了模拟搭建集群，就算有真实服务器也建议先在虚拟机上跑一遍大概流程。</p>
<h2 id="54-服务器">5.4 服务器</h2>
<p>部署<code>Hadoop</code>的真实服务器，这里使用了三台服务器进行搭建集群。</p>
<h1 id="6-动手吧">6 动手吧！</h1>
<p>准备工作做好后就开始动手吧！</p>
<p>由于篇幅略长所以分成了四篇文章方便查看：</p>
<ul>
<li><a href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-yi-ben-di-mo-shi/">（一）本地模式</a></li>
<li><a href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-er-wei-fen-bu-mo-shi/">（二）伪分布模式</a></li>
<li><a href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-san-wan-quan-fen-bu-mo-shi-xu-ni-ji/">（三）完全分布模式（虚拟机）</a></li>
<li><a href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-si-wan-quan-fen-bu-mo-shi-fu-wu-qi/">（四）完全分布模式（服务器）</a></li>
</ul>
<h1 id="7-结语">7 结语</h1>
<p>本文讲述了搭建<code>Hadoop</code>集群的三种方式，如无意外就可以搭建一个基本的<code>Hadoop</code>集群了。</p>
<p>但是，一般来说，并不能直接投入生产环境中使用，因为需要配合<code>ZooKeeper</code>搭建<code>HA（高可用）</code>集群，本文限于篇幅就不再叙述了。本文的初衷是教会读者如何搭建，至于<code>ZooKeeper</code>，网上有不少文章可以参考。最后希望读者看完之后能够对<code>Hadoop</code>有一个大概的认识，了解<code>Hadoop</code>的组成部分以及基本工作原理。</p>
<h1 id="8-参考">8 参考</h1>
<ul>
<li><a href="https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation">Hadoop3.3.0官方文档</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions">Hadoop-Java版本</a></li>
</ul>
<p><strong>如果觉得文章好看，欢迎点赞。</strong></p>
<p><strong>同时欢迎关注微信公众号：氷泠之路。</strong></p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20200806194605566.gif" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hadoop完整搭建过程（四）：完全分布模式（服务器）]]></title>
        <id>https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-si-wan-quan-fen-bu-mo-shi-fu-wu-qi/</id>
        <link href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-si-wan-quan-fen-bu-mo-shi-fu-wu-qi/">
        </link>
        <updated>2020-08-22T15:59:10.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#1-%E6%A6%82%E8%BF%B0">1 概述</a></li>
<li><a href="#2-%E7%BA%A6%E5%AE%9A">2 约定</a></li>
<li><a href="#3-%E5%8F%AF%E9%80%89%E6%9C%AC%E5%9C%B0host">3 （可选）本地<code>Host</code></a></li>
<li><a href="#4-ssh">4  <code>ssh</code></a></li>
<li><a href="#5-%E4%B8%BB%E6%9C%BA%E5%90%8D">5 主机名</a></li>
<li><a href="#6-%E9%85%8D%E7%BD%AE%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83">6 配置基本环境</a>
<ul>
<li><a href="#61-jdk">6.1 <code>JDK</code></a></li>
<li><a href="#62-hadoop">6.2 <code>Hadoop</code></a>
<ul>
<li><a href="#621-hadoop-envsh">6.2.1 <code>hadoop-env.sh</code></a></li>
<li><a href="#622-core-sitexml">6.2.2 <code>core-site.xml</code></a></li>
<li><a href="#623-hdfs-sitexml">6.2.3 <code>hdfs-site.xml</code></a></li>
<li><a href="#624-workers">6.2.4 <code>workers</code></a></li>
<li><a href="#625-%E5%A4%8D%E5%88%B6%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">6.2.5 复制配置文件</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#7-%E5%90%AF%E5%8A%A8">7 启动</a>
<ul>
<li><a href="#71-%E6%A0%BC%E5%BC%8F%E5%8C%96hdfs">7.1 格式化<code>HDFS</code></a></li>
<li><a href="#72-hadoop-envsh">7.2 <code>hadoop-env.sh</code></a></li>
<li><a href="#73-%E5%90%AF%E5%8A%A8">7.3 启动</a></li>
</ul>
</li>
<li><a href="#8-yarn">8 <code>YARN</code></a>
<ul>
<li><a href="#81-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">8.1 环境变量</a></li>
<li><a href="#82-yarn%E9%85%8D%E7%BD%AE">8.2 <code>YARN</code>配置</a></li>
<li><a href="#83-%E5%BC%80%E5%90%AFyarn">8.3 开启<code>YARN</code></a></li>
<li><a href="#84-%E6%B5%8B%E8%AF%95">8.4 测试</a></li>
</ul>
</li>
<li><a href="#9-%E5%8F%82%E8%80%83">9 参考</a></li>
</ul>
</p>
<h1 id="1-概述">1 概述</h1>
<p>上一篇文章介绍了如何使用虚拟机搭建集群，到了这篇文章就是实战了，使用真实的三台不同服务器进行<code>Hadoop</code>集群的搭建。具体步骤其实与虚拟机的差不多，但是由于安全组以及端口等等一些列的问题，会与虚拟机有所不同，废话不多说，下面正式开始。</p>
<h1 id="2-约定">2 约定</h1>
<ul>
<li><code>Master</code>节点的<code>ip</code>用<code>MasterIP</code>表示，主机名用<code>master</code>表示</li>
<li>两个<code>Worker</code>节点的<code>ip</code>用<code>Worker1IP</code>/<code>Worker2IP</code>表示，主机名用<code>worker1</code>/<code>worker2</code>表示</li>
<li>这里为了演示方便统一使用<code>root</code>用户登录，当然生产环境不会这样</li>
</ul>
<h1 id="3-可选本地host">3 （可选）本地<code>Host</code></h1>
<p>修改本地<code>Host</code>，方便使用主机名来进行操作：</p>
<pre><code class="language-bash">sudo vim /etc/hosts
# 添加
MaterIP master
Worker1IP worker1
Worker2IP worker2
</code></pre>
<h1 id="4-ssh">4  <code>ssh</code></h1>
<p>本机生成密钥对后复制公钥到三台服务器上：</p>
<pre><code class="language-bash">ssh-keygen -t ed25519 -a 100 # 使用更快更安全的ed25519算法而不是传统的RSA-3072/4096
ssh-copy-id root@master
ssh-copy-id root@worker1
ssh-copy-id root@worker2
</code></pre>
<p>这时可以直接使用<code>root@host</code>进行连接了：</p>
<pre><code class="language-bash">ssh root@master
ssh root@worker1
ssh root@worker2
</code></pre>
<p>不需要输入密码，如果不能连接或者需要输入密码请检查<code>/etc/ssh/sshd_config</code>或系统日志。</p>
<h1 id="5-主机名">5 主机名</h1>
<p>修改<code>Master</code>节点的主机名为<code>master</code>，两个<code>Worker</code>节点的主机名为<code>worker1</code>、<code>worker2</code>：</p>
<pre><code class="language-bash"># Master节点
vim /etc/hostname
master
# Worker1节点
# worker1
# Worker2节点
# worker2
</code></pre>
<p>同时修改<code>Host</code>：</p>
<pre><code class="language-bash"># Master节点
vim /etc/hosts
Worker1IP worker1
Worker2IP worker2

# Worker1节点
vim /etc/hosts
MasterIP master
Worker2IP worker2

# Worker1节点
vim /etc/hosts
MasterIP master
Worker1IP worker1
</code></pre>
<p>修改完成之后需要互<code>ping</code>测试：</p>
<pre><code class="language-bash">ping master
ping worker1
ping worker2
</code></pre>
<p><code>ping</code>不通的话应该是安全组的问题，开放<code>ICMP</code>协议即可：</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20200821110732939.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h1 id="6-配置基本环境">6 配置基本环境</h1>
<h2 id="61-jdk">6.1 <code>JDK</code></h2>
<p><code>scp</code>上传<code>OpenJDK 11</code>，解压并放置于<code>/usr/local/java</code>下，同时修改<code>PATH</code>：</p>
<pre><code class="language-bash">export PATH=$PATH:/usr/local/java/bin
</code></pre>
<p>如果原来的服务器装有了其他版本的<code>JDK</code>可以先卸载：</p>
<pre><code class="language-bash">yum remove java
</code></pre>
<p>注意设置环境变量后需要测试以下<code>java</code>，因为不同服务器的架构可能不一样：</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20200821133211530.png" alt="在这里插入图片描述" loading="lazy"></figure>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20200821133227441.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>比如笔者的<code>Master</code>节点为<code>aarch64</code>架构，而两个<code>Worker</code>都是<code>x86_64</code>架构，因此<code>Master</code>节点执行<code>java</code>时报错如下：</p>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20200821133338136.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>解决办法是通过<code>yum install</code>安装<code>OpenJDK11</code>：</p>
<pre><code class="language-bash">yum install java-11-openjdk
</code></pre>
<h2 id="62-hadoop">6.2 <code>Hadoop</code></h2>
<p><code>scp</code>上传<code>Hadoop 3.3.0</code>，解压并放置于<code>/usr/local/hadoop</code>下，注意选择对应的架构：</p>
<figure data-type="image" tabindex="5"><img src="https://img-blog.csdnimg.cn/20200821143835137.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>解压后修改以下四个配置文件：</p>
<ul>
<li><code>etc/hadoop/hadoop-env.sh</code></li>
<li><code>etc/hadoop/core-site.xml</code></li>
<li><code>etc/hadoop/hdfs-site.xml</code></li>
<li><code>etc/hadoop/workers</code></li>
</ul>
<h3 id="621-hadoop-envsh">6.2.1 <code>hadoop-env.sh</code></h3>
<p>修改<code>JAVA_HOME</code>环境变量即可：</p>
<pre><code class="language-bash">export JAVA_HOME=/usr/local/java # 修改为您的Java目录
</code></pre>
<h3 id="622-core-sitexml">6.2.2 <code>core-site.xml</code></h3>
<pre><code class="language-xml">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		&lt;value&gt;hdfs://master:9000&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/tmp&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<p>具体选项与虚拟机方式的设置相同，这里不再重复叙述。</p>
<h3 id="623-hdfs-sitexml">6.2.3 <code>hdfs-site.xml</code></h3>
<pre><code class="language-xml">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/namenode&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/datanode&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;2&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<h3 id="624-workers">6.2.4 <code>workers</code></h3>
<pre><code class="language-bash">worker1
worker2
</code></pre>
<h3 id="625-复制配置文件">6.2.5 复制配置文件</h3>
<pre><code class="language-bash"># 如果设置了端口以及私钥
# 加上 -P 端口 -i 私钥
scp /usr/local/hadoop/etc/hadoop/* worker1:/usr/local/hadoop/etc/hadoop/
scp /usr/local/hadoop/etc/hadoop/* worker2:/usr/local/hadoop/etc/hadoop/
</code></pre>
<h1 id="7-启动">7 启动</h1>
<h2 id="71-格式化hdfs">7.1 格式化<code>HDFS</code></h2>
<p>在<code>Master</code>中，首先格式化<code>HDFS</code></p>
<pre><code class="language-bash">cd /usr/local/hadoop
bin/hdfs namenode -format
</code></pre>
<p>如果配置文件没错的话就格式化成功了。</p>
<h2 id="72-hadoop-envsh">7.2 <code>hadoop-env.sh</code></h2>
<p>还是在<code>Master</code>中，修改<code>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</code>，末尾添加：</p>
<pre><code class="language-bash">HDFS_DATANODE_USER=root
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
</code></pre>
<h2 id="73-启动">7.3 启动</h2>
<p>首先<code>Master</code>开放<code>9000</code>以及<code>9870</code>端口（一般安全组开放即可，如果开启了防火墙<code>firewalld/iptables</code>则添加相应规则），并在<code>Master</code>节点中启动：</p>
<pre><code class="language-bash">sbin/start-dfs.sh
</code></pre>
<p>浏览器输入：</p>
<pre><code class="language-bash">MasterIP:9870
</code></pre>
<p>即可看到如下页面：</p>
<figure data-type="image" tabindex="6"><img src="https://img-blog.csdnimg.cn/20200821153852312.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>如果看到<code>Live Nodes</code>数量为0请查看<code>Worker</code>的日志，这里发现是端口的问题：</p>
<figure data-type="image" tabindex="7"><img src="https://img-blog.csdnimg.cn/20200821154029794.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>并且在配置了安全组，关闭了防火墙的情况下还是如此，则有可能是<code>Host</code>的问题，可以把<code>Master</code>节点中的：</p>
<pre><code class="language-bash"># /etc/hosts
127.0.0.1 master
</code></pre>
<p>删去，同样道理删去两个<code>Worker</code>中的：</p>
<pre><code class="language-bash"># /etc/hosts
127.0.0.1 worker1
127.0.0.1 worker2
</code></pre>
<h1 id="8-yarn">8 <code>YARN</code></h1>
<h2 id="81-环境变量">8.1 环境变量</h2>
<p>修改<code>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</code>，添加：</p>
<pre><code class="language-bash">export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
</code></pre>
<h2 id="82-yarn配置">8.2 <code>YARN</code>配置</h2>
<p>在两个<code>Worker</code>节点中修改<code>/usr/local/hadoop/etc/hadoop/yarn-site.xml</code>：</p>
<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
	&lt;value&gt;master&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h2 id="83-开启yarn">8.3 开启<code>YARN</code></h2>
<p><code>Master</code>节点中开启<code>YARN</code>：</p>
<pre><code class="language-bash">cd /usr/local/hadoop
sbin/start-yarn.sh
</code></pre>
<p>同时<code>Master</code>的安全组开放<code>8088</code>以及<code>8031</code>端口。</p>
<h2 id="84-测试">8.4 测试</h2>
<p>浏览器输入：</p>
<pre><code class="language-bash">MasterIP:8088
</code></pre>
<p>应该就可以访问如下页面了：</p>
<figure data-type="image" tabindex="8"><img src="https://img-blog.csdnimg.cn/20200821154539965.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>至此集群正式搭建完成。</p>
<h1 id="9-参考">9 参考</h1>
<ul>
<li><a href="https://www.cnblogs.com/duanxz/p/5142535.html">博客园-HDFS之五：Hadoop 拒绝远程 9000 端口访问</a></li>
<li><a href="https://medium.com/@jootorres_11979/how-to-set-up-a-hadoop-3-2-1-multi-node-cluster-on-ubuntu-18-04-2-nodes-567ca44a3b12">How To Set Up a Hadoop 3.2.1 Multi-Node Cluster on Ubuntu 18.04 (2 Nodes)</a></li>
<li><a href="https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/">How to Install and Set Up a 3-Node Hadoop Cluster</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hadoop完整搭建过程（三）：完全分布模式（虚拟机）]]></title>
        <id>https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-san-wan-quan-fen-bu-mo-shi-xu-ni-ji/</id>
        <link href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-san-wan-quan-fen-bu-mo-shi-xu-ni-ji/">
        </link>
        <updated>2020-08-22T15:58:42.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#1-%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E6%A8%A1%E5%BC%8F">1 完全分布模式</a></li>
<li><a href="#2-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85">2 虚拟机安装</a>
<ul>
<li><a href="#21-%E9%95%9C%E5%83%8F%E4%B8%8B%E8%BD%BD">2.1 镜像下载</a></li>
<li><a href="#22-%E5%AE%89%E8%A3%85">2.2 安装</a></li>
<li><a href="#23-%E5%90%AF%E5%8A%A8">2.3 启动</a></li>
</ul>
</li>
<li><a href="#3-ssh%E8%BF%9E%E6%8E%A5%E8%99%9A%E6%8B%9F%E6%9C%BA">3 <code>ssh</code>连接虚拟机</a></li>
<li><a href="#4-%E5%9F%BA%E6%9C%AC%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA">4 基本环境搭建</a>
<ul>
<li><a href="#41-jdk">4.1 <code>JDK</code></a></li>
<li><a href="#42-hadoop">4.2 <code>Hadoop</code></a></li>
</ul>
</li>
<li><a href="#5-%E5%85%8B%E9%9A%86">5 克隆</a></li>
<li><a href="#6-%E4%B8%BB%E6%9C%BA%E5%90%8Dip%E8%AE%BE%E7%BD%AE">6 主机名+<code>ip</code>设置</a></li>
<li><a href="#7-host%E8%AE%BE%E7%BD%AE">7 <code>Host</code>设置</a>
<ul>
<li><a href="#71-master%E8%8A%82%E7%82%B9">7.1 <code>Master</code>节点</a></li>
<li><a href="#72-worker1%E8%8A%82%E7%82%B9">7.2 <code>Worker1</code>节点</a></li>
<li><a href="#73-worker2%E8%8A%82%E7%82%B9">7.3 <code>Worker2</code>节点</a></li>
<li><a href="#74-%E4%BA%92ping%E6%B5%8B%E8%AF%95">7.4 互<code>ping</code>测试</a></li>
</ul>
</li>
<li><a href="#8-%E9%85%8D%E7%BD%AEssh">8 配置<code>ssh</code></a>
<ul>
<li><a href="#81-sshd%E6%9C%8D%E5%8A%A1">8.1 <code>sshd</code>服务</a></li>
<li><a href="#82-%E5%A4%8D%E5%88%B6%E5%85%AC%E9%92%A5">8.2 复制公钥</a></li>
<li><a href="#83-%E6%B5%8B%E8%AF%95">8.3 测试</a></li>
</ul>
</li>
<li><a href="#9-master%E8%8A%82%E7%82%B9hadoop%E9%85%8D%E7%BD%AE">9 <code>Master</code>节点<code>Hadoop</code>配置</a>
<ul>
<li><a href="#91-core-sitexml">9.1 <code>core-site.xml</code></a></li>
<li><a href="#92-hdfs-sitexml">9.2 <code>hdfs-site.xml</code></a></li>
<li><a href="#93-workers">9.3 <code>workers</code></a></li>
<li><a href="#94-%E5%A4%8D%E5%88%B6%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">9.4 复制配置文件</a></li>
</ul>
</li>
<li><a href="#10-hdfs%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%B9%B6%E5%90%AF%E5%8A%A8">10 <code>HDFS</code>格式化并启动</a>
<ul>
<li><a href="#101-%E5%90%AF%E5%8A%A8">10.1 启动</a></li>
<li><a href="#102-%E6%B5%8B%E8%AF%95">10.2 测试</a></li>
<li><a href="#103-%E9%98%B2%E7%81%AB%E5%A2%99">10.3 防火墙</a></li>
</ul>
</li>
<li><a href="#11-%E9%85%8D%E7%BD%AEyarn">11 配置<code>YARN</code></a>
<ul>
<li><a href="#111-yarn%E9%85%8D%E7%BD%AE">11.1 <code>YARN</code>配置</a></li>
<li><a href="#112-%E5%BC%80%E5%90%AFyarn">11.2 开启<code>YARN</code></a></li>
<li><a href="#113-%E6%B5%8B%E8%AF%95">11.3 测试</a></li>
</ul>
</li>
<li><a href="#12-%E5%8F%82%E8%80%83">12 参考</a></li>
</ul>
</p>
<h1 id="1-完全分布模式">1 完全分布模式</h1>
<p>完全分布模式是比本地模式与伪分布模式更加复杂的模式，真正利用多台Linux主机来进行部署<code>Hadoop</code>，对集群进行规划，使得<code>Hadoop</code>各个模块分别部署在不同的多台机器上，这篇文章介绍的是通过三台虚拟机进行集群配置的方式，主要步骤为：</p>
<ul>
<li>准备虚拟机：准备虚拟机基本环境</li>
<li><code>ip</code>+<code>Host</code>配置：手动设置虚拟机<code>ip</code>以及主机名，需要确保三台虚拟机能互相<code>ping</code>通</li>
<li><code>ssh</code>配置：生成密钥对后复制公钥到三台虚拟机中，使其能够实现无密码相互连接</li>
<li><code>Hadoop</code>配置：<code>core-site.xml</code>+<code>hdfs-site.xml</code>+<code>workers</code></li>
<li><code>YARN</code>配置：<code>yarn-site.xml</code></li>
</ul>
<h1 id="2-虚拟机安装">2 虚拟机安装</h1>
<p>需要使用到三台虚拟机，其中一台为<code>Master</code>节点，两台<code>Worker</code>节点，首先安装虚拟机并配置环境，最后进行测试。</p>
<h2 id="21-镜像下载">2.1 镜像下载</h2>
<p>使用<code>VirtualBox</code>进行虚拟机的安装，先去<code>CentOS</code><a href="https://www.centos.org/">官网</a>下载最新版本的镜像：</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/2020081519354985.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>这里有三种不同的镜像：</p>
<ul>
<li><code>boot</code>：网络安装版</li>
<li><code>dvd1</code>：完整版</li>
<li><code>minimal</code>：最小化安装版</li>
</ul>
<p>这里为了方便选择最小化安装版的，也就是不带<code>GUI</code>的。</p>
<h2 id="22-安装">2.2 安装</h2>
<p>下载后，打开<code>Virtual Box</code>并点击<code>New</code>，选择<code>专家模式</code>：</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20200815165142905.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>命名为<code>CentOSMaster</code>，作为<code>Master</code>节点，并且分配内存，这里是1G，如果觉得自己内存大的可以2G：</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/20200819230240508.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>磁盘30G足够，其他可以保持默认：</p>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20200819230314548.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>创建好后从设置中的存储中，选择下载的镜像：</p>
<figure data-type="image" tabindex="5"><img src="https://img-blog.csdnimg.cn/20200816003614166.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>启动后会提示选择启动盘，确定即可：</p>
<figure data-type="image" tabindex="6"><img src="https://img-blog.csdnimg.cn/20200819230540113.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>好了之后会出现如下提示画面，选择第一个安装：</p>
<figure data-type="image" tabindex="7"><img src="https://img-blog.csdnimg.cn/20200815165807673.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>等待一会后进入安装界面：</p>
<figure data-type="image" tabindex="8"><img src="https://img-blog.csdnimg.cn/20200815165925380.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>接下来对安装位置以及时区进行配置，首先选择安装位置：</p>
<figure data-type="image" tabindex="9"><img src="https://img-blog.csdnimg.cn/20200816003919460.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>由于是虚拟的单个空磁盘，选择自动分区即可：</p>
<figure data-type="image" tabindex="10"><img src="https://img-blog.csdnimg.cn/20200819230719284.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>时区这里可以选择中国的上海：</p>
<figure data-type="image" tabindex="11"><img src="https://img-blog.csdnimg.cn/2020081600413442.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>接着选择网络，首先修改主机名为<code>master</code>：</p>
<figure data-type="image" tabindex="12"><img src="https://img-blog.csdnimg.cn/20200819230849506.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>接着点击<code>Configure</code>：</p>
<figure data-type="image" tabindex="13"><img src="https://img-blog.csdnimg.cn/20200819230940825.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>添加<code>ip</code>地址以及<code>DNS</code>服务器，<code>ip</code>地址可以参考本机，比如笔者的机器本地<code>ip</code>为<code>192.168.1.7</code>，则：</p>
<ul>
<li>虚拟机的<code>ip</code>可以填<code>192.168.1.8</code></li>
<li>子网掩码一般为<code>255.255.255.0</code></li>
<li>默认网关为<code>192.168.1.1</code></li>
<li><code>DNS</code>服务器为<code>114.114.114.114</code>（当然也可以换其他的公共<code>DNS</code>比如阿里的<code>223.5.5.5</code>、百度的<code>180.76.76.76</code>等）</li>
</ul>
<figure data-type="image" tabindex="14"><img src="https://img-blog.csdnimg.cn/20200819231225948.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>点击<code>Save</code>后应用主机名并开启：</p>
<figure data-type="image" tabindex="15"><img src="https://img-blog.csdnimg.cn/20200819231405334.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>没问题的话就可以安装了：</p>
<figure data-type="image" tabindex="16"><img src="https://img-blog.csdnimg.cn/20200819231440342.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>安装的时候设置<code>root</code>用户的密码以及创建用户：</p>
<figure data-type="image" tabindex="17"><img src="https://img-blog.csdnimg.cn/20200819231558338.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>用户这里采用一个叫<code>hadoopuser</code>的用户，后面的操作都直接基于该用户：</p>
<figure data-type="image" tabindex="18"><img src="https://img-blog.csdnimg.cn/20200819231707374.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>等待一段时间后安装完成重启即可。</p>
<h2 id="23-启动">2.3 启动</h2>
<p>在启动之前首先把原来的镜像去掉：</p>
<figure data-type="image" tabindex="19"><img src="https://img-blog.csdnimg.cn/20200819235634486.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>启动后是黑框界面：</p>
<figure data-type="image" tabindex="20"><img src="https://img-blog.csdnimg.cn/2020081923592929.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>登录刚才创建的<code>hadoopuser</code>用户即可。</p>
<h1 id="3-ssh连接虚拟机">3 <code>ssh</code>连接虚拟机</h1>
<p>默认的话是不能连接外网的，需要在菜单栏中的<code>Devices</code>中选择<code>Network</code>，设置为<code>Bridged Adapter</code>（桥接模式）：</p>
<figure data-type="image" tabindex="21"><img src="https://img-blog.csdnimg.cn/20200820000355903.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>使用<code>ping</code>测试：</p>
<figure data-type="image" tabindex="22"><img src="https://img-blog.csdnimg.cn/20200820000543363.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>接着可以测试能否<code>ping</code>通本地机器：</p>
<figure data-type="image" tabindex="23"><img src="https://img-blog.csdnimg.cn/20200820000606825.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>通了之后可以通过<code>ssh</code>连接虚拟机，像平时操作服务器一样，在本地终端中连接虚拟机，首先添加指纹：</p>
<figure data-type="image" tabindex="24"><img src="https://img-blog.csdnimg.cn/20200820000839756.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>接着输入密码连接即可：</p>
<figure data-type="image" tabindex="25"><img src="https://img-blog.csdnimg.cn/20200820000915492.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>如果想偷懒可以使用密钥连接的方式，在本地机器中：</p>
<pre><code class="language-bash">ssh-keygen -t ed25519 -a 100
ssh-copy-id -i ~/.ssh/id_ed25519.pub hadoopuser@192.168.1.8
</code></pre>
<h1 id="4-基本环境搭建">4 基本环境搭建</h1>
<p>基本环境搭建就是安装<code>JDK</code>以及<code>Hadoop</code>，使用<code>scp</code>上传<code>OpenJDK</code>以及<code>Hadoop</code>。</p>
<h2 id="41-jdk">4.1 <code>JDK</code></h2>
<p>首先去下载<code>OpenJDK</code>，然后在本地机器上使用<code>scp</code>上传：</p>
<pre><code class="language-bash">scp openjdk-11+28_linux-x64_bin.tar.gz hadoopuser@192.168.1.8:/home/hadoopuser
</code></pre>
<p>接着在本地上切换到连接虚拟机的<code>ssh</code>中，</p>
<pre><code class="language-bash">cd ~
tar -zxvf openjdk-11+28_linux-x64_bin.tar.gz 
sudo mv jdk-11 /usr/local/java
</code></pre>
<p>下一步是编辑<code>/etc/profile</code>，添加<code>bin</code>到环境变量中，在末尾添加：</p>
<pre><code class="language-bash">sudo vim /etc/profile
# 没有vim请使用vi
# 或安装：sudo yum install vim
# 添加
export PATH=$PATH:/usr/local/java/bin
</code></pre>
<p>然后：</p>
<pre><code class="language-bash">. /etc/profile
</code></pre>
<p>测试：</p>
<figure data-type="image" tabindex="26"><img src="https://img-blog.csdnimg.cn/2020082000223989.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="42-hadoop">4.2 <code>Hadoop</code></h2>
<p><code>Hadoop</code>的压缩包<code>scp</code>上传到虚拟机后，解压并移动到<code>/usr/local</code>：</p>
<pre><code class="language-bash">scp hadoop-3.3.0.tar.gz hadoopuser@192.168.1.8:/home/hadoopuser
</code></pre>
<p>虚拟机<code>ssh</code>终端：</p>
<pre><code class="language-bash">cd ~
tar -xvf hadoop-3.3.0.tar.gz
sudo mv hadoop-3.3.0 /usr/local/hadoop
</code></pre>
<p>同时修改<code>etc/hadoop/hadoop-env.sh</code>配置文件，填入<code>Java</code>路径：</p>
<pre><code class="language-bash">sudo vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh
# 填入
export JAVA_HOME=/usr/local/java # 修改为您的Java目录
</code></pre>
<h1 id="5-克隆">5 克隆</h1>
<p>因为需要一个<code>Master</code>节点以及两个<code>Worker</code>节点，将<code>Master</code>节点关机，并选择配置好的<code>CentOSMaster</code>，右键进行克隆：</p>
<figure data-type="image" tabindex="27"><img src="https://img-blog.csdnimg.cn/20200819151039911.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>并选择完全克隆：</p>
<figure data-type="image" tabindex="28"><img src="https://img-blog.csdnimg.cn/20200819151056670.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>克隆出<code>CentOSWorker1</code>以及<code>CentOSWorker2</code>。</p>
<h1 id="6-主机名ip设置">6 主机名+<code>ip</code>设置</h1>
<p>这里的两个<code>Worker</code>节点以<code>Worker1</code>以及<code>Worker2</code>命名，首先操作<code>Worker1</code>，修改主机名：</p>
<pre><code class="language-bash">sudo vim /etc/hostname
# 输入
# worker1
</code></pre>
<p>对于<code>ip</code>，由于<code>Master</code>节点的<code>ip</code>为<code>192.168.1.8</code>，因此这里修改两个<code>Worker</code>的节点分别为：</p>
<ul>
<li><code>192.168.1.9</code></li>
<li><code>192.168.1.10</code></li>
</ul>
<pre><code class="language-bash">sudo vim /etc/sysconfig/network-scripts/ifcfg-xxxx # 该文件因人而异
# 修改IPADDR
IPADDR=192.168.1.9
</code></pre>
<p>修改完成后重启<code>Worker1</code>，对<code>Worker2</code>进行同样的修改主机名以及<code>ip</code>操作。</p>
<h1 id="7-host设置">7 <code>Host</code>设置</h1>
<p>需要在<code>Master</code>以及<code>Worker</code>节点进行<code>Host</code>设置：</p>
<h2 id="71-master节点">7.1 <code>Master</code>节点</h2>
<pre><code class="language-bash">sudo vim /etc/hosts
# 添加
192.168.1.9 worker1 # 与上面的ip对应一致
192.168.1.10 worker2
</code></pre>
<figure data-type="image" tabindex="29"><img src="https://img-blog.csdnimg.cn/20200820004851111.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="72-worker1节点">7.2 <code>Worker1</code>节点</h2>
<pre><code class="language-bash">sudo vim /etc/hosts
# 添加
192.168.1.8 master
192.168.1.10 worker2
</code></pre>
<figure data-type="image" tabindex="30"><img src="https://img-blog.csdnimg.cn/20200820004923697.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="73-worker2节点">7.3 <code>Worker2</code>节点</h2>
<pre><code class="language-bash">sudo vim /etc/hosts
# 添加
192.168.1.8 master
192.168.1.9 worker1
</code></pre>
<figure data-type="image" tabindex="31"><img src="https://img-blog.csdnimg.cn/20200820005048835.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="74-互ping测试">7.4 互<code>ping</code>测试</h2>
<p>在三台虚拟机中的其中一台<code>ping</code>另外两台的<code>ip</code>或者主机名，测试通过后就可以进行下一步了，这里使用<code>Worker1</code>节点测试：</p>
<figure data-type="image" tabindex="32"><img src="https://img-blog.csdnimg.cn/20200820005253707.png" alt="在这里插入图片描述" loading="lazy"></figure>
<figure data-type="image" tabindex="33"><img src="https://img-blog.csdnimg.cn/20200820005326525.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h1 id="8-配置ssh">8 配置<code>ssh</code></h1>
<h2 id="81-sshd服务">8.1 <code>sshd</code>服务</h2>
<p>需要在三个节点（包括自身）之间配置<code>ssh</code>无密码（密钥）连接，首先使用</p>
<pre><code class="language-bash">systemctl status sshd
</code></pre>
<p>检查<code>sshd</code>服务是否开启，没开启的使用</p>
<pre><code class="language-bash">systemctl start sshd
</code></pre>
<p>开启。</p>
<h2 id="82-复制公钥">8.2 复制公钥</h2>
<p>三个节点都进行如下操作：</p>
<pre><code class="language-bash">ssh-keygen -t ed25519 -a 100
ssh-copy-id master
ssh-copy-id worker1
ssh-copy-id worker2
</code></pre>
<h2 id="83-测试">8.3 测试</h2>
<p>在其中一个节点中直接<code>ssh</code>连接其他节点，无需密码即可登录，比如在<code>Master</code>节点中：</p>
<pre><code class="language-bash">ssh master # 都是hadoopuser用户，所以省略了用户
ssh worker1
ssh worker2
</code></pre>
<h1 id="9-master节点hadoop配置">9 <code>Master</code>节点<code>Hadoop</code>配置</h1>
<p>在<code>Master</code>节点中，修改以下三个配置文件：</p>
<ul>
<li><code>HADOOP/etc/hadoop/core-site.xml</code></li>
<li><code>HADOOP/etc/hadoop/hdfs-site.xml</code></li>
<li><code>HADOOP/etc/hadoop/workers</code></li>
</ul>
<h2 id="91-core-sitexml">9.1 <code>core-site.xml</code></h2>
<pre><code class="language-xml">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		&lt;value&gt;hdfs://master:9000&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/tmp&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li><code>fs.defaultFS</code>：<code>NameNode</code>地址</li>
<li><code>hadoop.tmp.dir</code>：<code>Hadoop</code>临时目录</li>
</ul>
<h2 id="92-hdfs-sitexml">9.2 <code>hdfs-site.xml</code></h2>
<pre><code class="language-xml">&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/namenode&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;/usr/local/hadoop/data/datanode&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;2&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li><code>dfs.namenode.name.dir</code>：保存<code>FSImage</code>的目录，存放<code>NameNode</code>的<code>metadata</code></li>
<li><code>dfs.datanode.data.dir</code>：保存<code>HDFS</code>数据的目录，存放<code>DataNode</code>的多个数据块</li>
<li><code>dfs.replication</code>：<code>HDFS</code>存储的临时备份数量，有两个<code>Worker</code>节点，因此数值为<code>2</code></li>
</ul>
<h2 id="93-workers">9.3 <code>workers</code></h2>
<p>最后修改<code>workers</code>，输入（与上面设置的主机名一致）：</p>
<pre><code class="language-bash">worker1
worker2
</code></pre>
<h2 id="94-复制配置文件">9.4 复制配置文件</h2>
<p>把<code>Master</code>节点的配置复制到<code>Worker</code>节点：</p>
<pre><code class="language-bash">scp /usr/local/hadoop/etc/hadoop/* worker1:/usr/local/hadoop/etc/hadoop/
scp /usr/local/hadoop/etc/hadoop/* worker2:/usr/local/hadoop/etc/hadoop/
</code></pre>
<h1 id="10-hdfs格式化并启动">10 <code>HDFS</code>格式化并启动</h1>
<h2 id="101-启动">10.1 启动</h2>
<p>在<code>Master</code>节点中：</p>
<pre><code class="language-bash">cd /usr/local/hadoop
bin/hdfs namenode -format
sbin/start-dfs.sh
</code></pre>
<p>运行后可以通过<code>jps</code>命令查看：</p>
<figure data-type="image" tabindex="34"><img src="https://img-blog.csdnimg.cn/2020082001293086.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>在<code>Worker</code>节点中：</p>
<figure data-type="image" tabindex="35"><img src="https://img-blog.csdnimg.cn/20200820012948217.png" alt="在这里插入图片描述" loading="lazy"></figure>
<figure data-type="image" tabindex="36"><img src="https://img-blog.csdnimg.cn/20200820013013547.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="102-测试">10.2 测试</h2>
<p>浏览器输入：</p>
<pre><code class="language-bash">master:9870
# 如果没有修改本机Host可以输入
# 192.168.1.8:9870
</code></pre>
<p>但是。。。</p>
<figure data-type="image" tabindex="37"><img src="https://img-blog.csdnimg.cn/20200820020506260.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>本以为做了这么多能看到成果了。</p>
<p>然后检查过了一遍本机+虚拟机<code>Host</code>，还有<code>Hadoop</code>的配置文件，都没有问题。</p>
<p>最后，</p>
<p>才定位到问题是</p>
<p>防火墙。</p>
<h2 id="103-防火墙">10.3 防火墙</h2>
<p><code>CentOS8</code>默认开启了防火墙，可以使用：</p>
<pre><code class="language-bash">systemctl status firewalld
</code></pre>
<p>查看防火墙状态。</p>
<p>由于是通过<code>9870</code>端口访问，首先查询<code>9870</code>是否开放，<code>Master</code>节点中输入：</p>
<pre><code class="language-bash">sudo firewall-cmd --query-port=9870/tcp
# 或
sudo firewall-cmd --list-ports
</code></pre>
<p>如果输出为<code>no</code>：</p>
<figure data-type="image" tabindex="38"><img src="https://img-blog.csdnimg.cn/20200820021105100.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>则表示没有开放，手动开放即可：</p>
<pre><code class="language-bash">sudo firewall-cmd --add-port=9870/tcp --permanent
sudo firewall-cmd --reload # 使其生效
</code></pre>
<figure data-type="image" tabindex="39"><img src="https://img-blog.csdnimg.cn/20200820021307949.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>再次在浏览器输入：</p>
<pre><code class="language-bash">master:9870
# 如果没有修改本地Host
# 192.168.1.8:9870
</code></pre>
<p>可以看到一个友好的页面了：</p>
<figure data-type="image" tabindex="40"><img src="https://img-blog.csdnimg.cn/20200821005959849.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>但是，有一个问题就是这里没有显示<code>Worker</code>节点，上图中的<code>Live Nodes</code>数目为0 ，而<code>Datanodes</code>这里什么也没有显示：</p>
<figure data-type="image" tabindex="41"><img src="https://img-blog.csdnimg.cn/20200821010116369.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>但是在<code>Worker</code>节点中的确可以看到有<code>Datanode</code>的进程了：</p>
<figure data-type="image" tabindex="42"><img src="https://img-blog.csdnimg.cn/20200821010233268.png" alt="在这里插入图片描述" loading="lazy"></figure>
<figure data-type="image" tabindex="43"><img src="https://img-blog.csdnimg.cn/2020082101024767.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>查看<code>Worker</code>节点的日志（<code>/usr/local/hadoop/logs/hadoop-hadoopuser-datanode-worker1.log</code>）可以看到应该是<code>Master</code>节点<code>9000</code>端口的没有开启的问题：</p>
<figure data-type="image" tabindex="44"><img src="https://img-blog.csdnimg.cn/20200821010415450.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>回到<code>Master</code>节点，先执行<code>stop-dfs.sh</code>关闭，并开放<code>9000</code>端口后执行<code>start-dfs.sh</code>开启：</p>
<pre><code class="language-bash">/usr/local/hadoop/sbin/stop-dfs.sh
sudo firewall-cmd --add-port=9000/tcp --permanent
sudo firewall-cmd --reload
/usr/local/hadoop/sbin/start-dfs.sh
</code></pre>
<p>再次在浏览器访问：</p>
<pre><code class="language-bash">master:9000
# 或
# 192.168.1.8:9000
</code></pre>
<p>这时候就可以看见<code>Worker</code>节点了：</p>
<figure data-type="image" tabindex="45"><img src="https://img-blog.csdnimg.cn/20200821010954445.png" alt="在这里插入图片描述" loading="lazy"></figure>
<figure data-type="image" tabindex="46"><img src="https://img-blog.csdnimg.cn/20200821011015564.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h1 id="11-配置yarn">11 配置<code>YARN</code></h1>
<h2 id="111-yarn配置">11.1 <code>YARN</code>配置</h2>
<p>在两个<code>Worker</code>节点中修改<code>/usr/local/hadoop/etc/hadoop/yarn-site.xml</code>：</p>
<pre><code class="language-xml">&lt;property&gt;
	&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
	&lt;value&gt;master&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h2 id="112-开启yarn">11.2 开启<code>YARN</code></h2>
<p><code>Master</code>节点中开启<code>YARN</code>：</p>
<pre><code class="language-bash">cd /usr/local/hadoop
sbin/start-yarn.sh
</code></pre>
<p>同时开放<code>8088</code>端口为下面的测试做准备：</p>
<pre><code class="language-bash">sudo firewall-cmd --add-port=8088/tcp --permanent
sudo firewall-cmd --reload
</code></pre>
<h2 id="113-测试">11.3 测试</h2>
<p>浏览器输入：</p>
<pre><code class="language-bash">master:8088
# 或
# 192.168.1.8:8088
</code></pre>
<p>应该就可以访问如下页面了：</p>
<figure data-type="image" tabindex="47"><img src="https://img-blog.csdnimg.cn/20200820221044468.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>同样道理没有看到<code>Worker</code>节点，查看<code>Worker</code>节点的日志，发现也是端口的问题：</p>
<figure data-type="image" tabindex="48"><img src="https://img-blog.csdnimg.cn/20200821011230192.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p><code>Master</code>节点先关闭<code>YARN</code>，开放<code>8031</code>端口，并重启<code>YARN</code>：</p>
<pre><code class="language-bash">/usr/local/hadoop/sbin/stop-yarn.sh
sudo firewall-cmd --add-port=8031/tcp --permanent
sudo firewall-cmd --reload
/usr/local/hadoop/sbin/start-yarn.sh
</code></pre>
<p>再次访问：</p>
<pre><code class="language-bash">master:8088
# 或
# 192.168.1.8:8088
</code></pre>
<p>就可以看到<code>Worker</code>节点了：</p>
<figure data-type="image" tabindex="49"><img src="https://img-blog.csdnimg.cn/20200821011534482.png" alt="在这里插入图片描述" loading="lazy"></figure>
<figure data-type="image" tabindex="50"><img src="https://img-blog.csdnimg.cn/20200821011552273.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>至此，虚拟机组成<code>Hadoop</code>集群正式搭建完成。</p>
<h1 id="12-参考">12 参考</h1>
<ul>
<li><a href="https://blog.csdn.net/GitChat/article/details/77849331">CSDN-GitChat·大数据 | 史上最详细的Hadoop环境搭建</a></li>
<li><a href="https://medium.com/@jootorres_11979/how-to-set-up-a-hadoop-3-2-1-multi-node-cluster-on-ubuntu-18-04-2-nodes-567ca44a3b12">How To Set Up a Hadoop 3.2.1 Multi-Node Cluster on Ubuntu 18.04 (2 Nodes)</a></li>
<li><a href="https://www.linode.com/docs/databases/hadoop/how-to-install-and-set-up-hadoop-cluster/">How to Install and Set Up a 3-Node Hadoop Cluster</a></li>
<li><a href="https://blog.csdn.net/u010486658/article/details/70871940#t9">CSDN-virtualBox实现主机和虚拟机相互ping通,配置静态IP地址</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hadoop完整搭建过程（二）：伪分布模式]]></title>
        <id>https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-er-wei-fen-bu-mo-shi/</id>
        <link href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-er-wei-fen-bu-mo-shi/">
        </link>
        <updated>2020-08-22T15:57:59.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#1-%E4%BC%AA%E5%88%86%E5%B8%83%E6%A8%A1%E5%BC%8F">1 伪分布模式</a></li>
<li><a href="#2-hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">2 <code>Hadoop</code>配置文件</a>
<ul>
<li><a href="#21-core-sitexml">2.1 <code>core-site.xml</code></a></li>
<li><a href="#22-hdfs-sitexml">2.2 <code>hdfs-site.xml</code></a></li>
<li><a href="#23-hadoop-envsh">2.3 <code>hadoop-env.sh</code></a></li>
</ul>
</li>
<li><a href="#3-%E6%9C%AC%E5%9C%B0%E6%97%A0%E5%AF%86%E7%A0%81ssh%E8%BF%9E%E6%8E%A5">3 本地无密码<code>ssh</code>连接</a></li>
<li><a href="#4-%E8%BF%90%E8%A1%8C">4 运行</a>
<ul>
<li><a href="#41-%E6%A0%BC%E5%BC%8F%E5%8C%96hdfs">4.1 格式化<code>HDFS</code></a></li>
<li><a href="#42-%E5%90%AF%E5%8A%A8namenode">4.2 启动<code>NameNode</code></a></li>
<li><a href="#43-%E6%B5%8B%E8%AF%95">4.3 测试</a></li>
</ul>
</li>
<li><a href="#5-%E4%BD%BF%E7%94%A8yarn%E9%85%8D%E7%BD%AE">5 使用<code>YARN</code>配置</a>
<ul>
<li><a href="#51-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">5.1 配置文件</a>
<ul>
<li><a href="#511-mapred-sitexml">5.1.1 <code>mapred-site.xml</code></a></li>
<li><a href="#512-yarn-sitexml">5.1.2 <code>yarn-site.xml</code></a></li>
</ul>
</li>
<li><a href="#52-%E8%BF%90%E8%A1%8C">5.2 运行</a></li>
</ul>
</li>
<li><a href="#6-%E5%8F%82%E8%80%83">6 参考</a></li>
</ul>
</p>
<h1 id="1-伪分布模式">1 伪分布模式</h1>
<p>伪分布模式是运行在单个节点以及多个Java进程上的模式。相比起本地模式，需要进行更多配置文件的设置以及<code>ssh</code>、<code>YARN</code>相关设置。</p>
<h1 id="2-hadoop配置文件">2 <code>Hadoop</code>配置文件</h1>
<p>修改<code>Hadoop</code>安装目录下的三个配置文件：</p>
<ul>
<li><code>etc/hadoop/core-site.xml</code></li>
<li><code>etc/hadoop/hdfs-site.xml</code></li>
<li><code>etc/hadoop/hadoop-env.sh</code></li>
</ul>
<h2 id="21-core-sitexml">2.1 <code>core-site.xml</code></h2>
<p>首先修改<code>core-site.xml</code>：</p>
<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
    	&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    	&lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li><code>fs.defaultFS</code>设置的是<code>HDFS</code>的地址，设置运行在本地的<code>9000</code>端口上</li>
<li><code>hadoop.tmp.dir</code>设置的是临时目录，如果没有设置的话默认在<code>/tmp/hadoop-${user.name}</code>中，系统重启后会导致数据丢失，因此修改这个临时目录的路径</li>
</ul>
<p>接着创建该临时目录：</p>
<pre><code class="language-bash">mkdir -p /usr/local/hadoop/tmp
</code></pre>
<h2 id="22-hdfs-sitexml">2.2 <code>hdfs-site.xml</code></h2>
<p>接着修改<code>hdfs-site.xml</code>：</p>
<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<p><code>dfs.replication</code>设置的是<code>HDFS</code>存储的临时备份数量，因为伪分布模式中只有一个节点，所以设置为<code>1</code>。</p>
<h2 id="23-hadoop-envsh">2.3 <code>hadoop-env.sh</code></h2>
<p>修改该文件添加<code>JAVA_HOME</code>环境变量，就算<code>JAVA_HOME</code>在</p>
<ul>
<li><code>~/.bashrc</code></li>
<li><code>~/.bash_profile</code></li>
<li><code>/etc/profile</code></li>
</ul>
<p>等中设置了，运行时也是会提示找不到<code>JAVA_HOME</code>，因此需要手动在<code>hadoop-env.sh</code>中设置<code>JAVA_HOME</code>：</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20200818111428437.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h1 id="3-本地无密码ssh连接">3 本地无密码<code>ssh</code>连接</h1>
<p>下一步需要设置本地无密码<code>ssh</code>连接，首先先检查确保开启<code>sshd</code>服务：</p>
<pre><code class="language-bash">systemctl status sshd
</code></pre>
<p>开启后可以直接<code>localhost</code>连接：</p>
<pre><code class="language-bash">ssh localhost
</code></pre>
<p>输入自己的用户密码后就可以访问了，但是这里需要的是无密码连接，因此配置密钥认证连接的方式：</p>
<pre><code class="language-bash">ssh-keygen -t ed25519 -a 100 
cat ~/.ssh/id_25519.pub &gt;&gt; ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys
</code></pre>
<p>这里生成公私钥后把公钥添加到<code>authorized_keys</code>中，并且修改权限，需要注意<code>600</code>权限，只能本用户有写权限。</p>
<p>然后直接<code>ssh localhost</code>就可以连接本地主机了。</p>
<h1 id="4-运行">4 运行</h1>
<h2 id="41-格式化hdfs">4.1 格式化<code>HDFS</code></h2>
<p>这里以单一节点的模式运行，首先格式化<code>HDFS</code>：</p>
<pre><code class="language-bash"># HADOOP为Hadoop安装目录
HADOOP/bin/hdfs namenode -format
</code></pre>
<p>格式化是对<code>HDFS</code>中的<code>DataNode</code>进行分块，统计所有分块后的初始元数据，存储在<code>NameNode</code>中。</p>
<p>格式化成功后会在上面配置文件中设置的临时目录中生成<code>dfs</code>目录，如下所示：</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20200818020828662.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>里面只有一个目录：<code>dfs/name/current</code>，其中<code>tmp/dfs/name/current</code>的文件如下：</p>
<figure data-type="image" tabindex="3"><img src="https://img-blog.csdnimg.cn/2020081802122850.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>文件说明如下：</p>
<ul>
<li><code>fsimage</code>：<code>NameNode</code>元数据在内存满后，持久化保存到的文件</li>
<li><code>fsimage*.md5</code>：校验文件，用于校验<code>fsimage</code>的完整性</li>
<li><code>seen_txid</code>：存放<code>transactionID</code>文件，<code>format</code>之后为0,表示<code>NameNode</code>里面的<code>edits_*</code>文件的尾数</li>
<li><code>VERSION</code>：保存创建时间，<code>namespaceID</code>、<code>blockpoolID</code>、<code>storageType</code>、<code>cTime</code>、<code>clusterID</code>、<code>layoutVersion</code></li>
</ul>
<p>关于<code>VERSION</code>的说明：</p>
<ul>
<li><code>namespaceID</code>：<code>HDFS</code>唯一标识符，在<code>HDFS</code>首次格式化后生成</li>
<li><code>blockpoolID</code>：标识一个<code>block pool</code>，跨集群全局唯一</li>
<li><code>storageType</code>：存储什么进程的数据结构信息</li>
<li><code>cTime</code>：创建时间</li>
<li><code>clusterID</code>：系统生成或指定的集群<code>ID</code>，可以使用<code>-clusterid</code>指定</li>
<li><code>layoutVersion</code>：表示<code>HDFS</code>永久性数据结构版本的信息</li>
</ul>
<h2 id="42-启动namenode">4.2 启动<code>NameNode</code></h2>
<pre><code class="language-bash">HADOOP/sbin/start-dfs.sh
</code></pre>
<p>然后可以通过</p>
<pre><code class="language-bash">localhost:9870
</code></pre>
<p>访问<code>NameNode</code>：</p>
<figure data-type="image" tabindex="4"><img src="https://img-blog.csdnimg.cn/20200818111545267.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h2 id="43-测试">4.3 测试</h2>
<p>生成输入目录，并使用配置文件作为输入：</p>
<pre><code class="language-bash">bin/hdfs dfs -mkdir /user
bin/hdfs dfs -mkdir /user/USER_NAME # USER_NAME为您的用户名
bin/hdfs dfs -mkdir input
bin/hdfs dfs -put etc/hadoop/*.xml input
</code></pre>
<p>测试：</p>
<pre><code class="language-bash">bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar grep input output 'dfs[a-z.]+'
</code></pre>
<p>获取输出：</p>
<pre><code class="language-bash">bin/hdfs dfs -get output output # 复制输出到output目录
cat output/*
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://img-blog.csdnimg.cn/20200818112311395.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>停止：</p>
<pre><code class="language-bash">sbin/stop-hdfs.sh
</code></pre>
<h1 id="5-使用yarn配置">5 使用<code>YARN</code>配置</h1>
<p>除了可以将单个节点以伪分布模式启动，还可以通过<code>YARN</code>统一调度，只需要适当修改配置文件。</p>
<h2 id="51-配置文件">5.1 配置文件</h2>
<p>修改以下文件：</p>
<ul>
<li><code>HADOOP/etc/hadoop/mapred-site.xml</code></li>
<li><code>HADOOP/etc/hadoop/yarn-site.xml</code></li>
</ul>
<h3 id="511-mapred-sitexml">5.1.1 <code>mapred-site.xml</code></h3>
<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;
        &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li><code>mapreduce.framework.name</code>指定了<code>MapReduce</code>运行在<code>YARN</code>上</li>
<li><code>mapreduce.application.classpath</code>指定了类路径</li>
</ul>
<h3 id="512-yarn-sitexml">5.1.2 <code>yarn-site.xml</code></h3>
<pre><code class="language-xml">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li><code>yarn.nodemanager.aux-services</code>：运行在<code>NodeManager</code>上运行的附属服务</li>
<li><code>yarn.nodemanager.env-whitelist</code>：环境变量通过从<code>NodeManagers</code>的容器继承的环境属性</li>
</ul>
<h2 id="52-运行">5.2 运行</h2>
<pre><code class="language-bash">sbin/start-yarn.sh
</code></pre>
<p>运行后就可以通过</p>
<pre><code class="language-bash">localhost:8088
</code></pre>
<p>访问：</p>
<figure data-type="image" tabindex="6"><img src="https://img-blog.csdnimg.cn/20200818115139159.png" alt="在这里插入图片描述" loading="lazy"></figure>
<p>停止：</p>
<pre><code class="language-bash">sbin/stop-yarn.sh
</code></pre>
<h1 id="6-参考">6 参考</h1>
<ul>
<li><a href="https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/SingleCluster.html#Pseudo-Distributed_Operation">Hadoop3.3.0官方文档</a></li>
<li><a href="https://blog.csdn.net/GitChat/article/details/77849331#t2">CSDN-GitChat·大数据 | 史上最详细的Hadoop环境搭建</a></li>
<li><a href="https://blog.csdn.net/levy_cui/article/details/60144621">CSDN-Hadoop Namenode元数据文件 Fsimage、editlog、seen_txid说明</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hadoop完整搭建过程（一）：本地模式]]></title>
        <id>https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-yi-ben-di-mo-shi/</id>
        <link href="https://2293736867.github.io/post/hadoop-wan-zheng-da-jian-guo-cheng-yi-ben-di-mo-shi/">
        </link>
        <updated>2020-08-22T15:57:31.000Z</updated>
        <content type="html"><![CDATA[<p><ul class="markdownIt-TOC">
<li><a href="#1-%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F">1 本地模式</a></li>
<li><a href="#2-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">2 准备工作</a></li>
<li><a href="#3-%E4%BD%BF%E7%94%A8">3 使用</a></li>
<li><a href="#4-%E8%BE%93%E5%87%BA">4 输出</a></li>
<li><a href="#5-%E5%8F%82%E8%80%83">5 参考</a></li>
</ul>
</p>
<h1 id="1-本地模式">1 本地模式</h1>
<p>本地模式是最简单的模式，所有模块都运行在一个<code>JVM</code>进程中，使用本地文件系统而不是<code>HDFS</code>。</p>
<p>本地模式主要是用于本地开发过程中的运行调试用，下载后的<code>Hadoop</code>不需要设置默认就是本地模式。</p>
<h1 id="2-准备工作">2 准备工作</h1>
<p>笔者喜欢把<code>JDK</code>放在<code>/usr/local</code>下，运行前请确保设置了<code>JAVA_HOME</code>，注意是在<code>etc/hadoop/hadoop-env.sh</code>中设置：</p>
<pre><code class="language-bash">tar -zxvf openjdk-11+28_linux-x64_bin.tar.gz
sudo mv openjdk-11+28_linux-x64_bin /usr/local/java
sudo vim HADOOP/etc/hadoop/hadoop-env.sh # HADOOP为Hadoop安装目录
# 输入
export JAVA_HOME=/usr/local/java
</code></pre>
<h1 id="3-使用">3 使用</h1>
<p>官网关于该模式没有太多的描述，只有一个使用默认配置文件作为输入，然后匹配正则表达式作为输出的简单例子：</p>
<pre><code class="language-bash"># HADOOP表示Hadoop安装目录
mkdir input
cp HADOOP/etc/hadoop/*.xml input
HADOOP/bin/hadoop jar HADOOP/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar grep input output 'dfs[a-z.]+'
cat output/*
</code></pre>
<p>从下图的<code>id</code>可以看出是以本地模式工作的：</p>
<figure data-type="image" tabindex="1"><img src="https://img-blog.csdnimg.cn/20200817190044114.png" alt="在这里插入图片描述" loading="lazy"></figure>
<h1 id="4-输出">4 输出</h1>
<p>输出文件夹<code>output</code>有两个文件：</p>
<figure data-type="image" tabindex="2"><img src="https://img-blog.csdnimg.cn/20200817180046955.png#pic_center" alt="在这里插入图片描述" loading="lazy"></figure>
<ul>
<li><code>_SUCCESS</code>：是个空文件，表示运行成功</li>
<li><code>part-r-00000</code>：输出结果文件，词数统计</li>
</ul>
<p><code>part-r-00000</code>结果如上图所示。</p>
<p>实际上本地模式不需要特别的处理，因为默认就是本地模式。</p>
<h1 id="5-参考">5 参考</h1>
<ul>
<li><a href="https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation">Hadoop3.3.0官方文档</a></li>
</ul>
]]></content>
    </entry>
</feed>